{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a famous library named TensorFlow (which is now available in version 2+) and in particular one of its subpackages, Keras, together with some utilities libraries like: \n",
    "\n",
    "- Matplotlib (for visualization);\n",
    "- Numpy (to work with arrays);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Runtime\n",
    "\n",
    "Neural Network training requires high parallel computation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 12:13:53.194797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Check tensorflow version (must be >2!)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a dataset\n",
    "\n",
    "To train a Neural Network model, we will need to load in memory a dataset. You can load it in lots of ways, depending on the time of data that you need.\n",
    "\n",
    "we will use built-in data on keras. In particoular, we are interested in:\n",
    "\n",
    "- Fashion-MNIST: It is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. \n",
    "\n",
    "we will download the dataset locally and experiment with it.\n",
    "You can visualize the data [here](https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=fashion_mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dimension: Input (60000, 28, 28), Output (60000,)\n",
      "Test set dimension: Input (10000, 28, 28), Output (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Import keras dataset Fashion Mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Check data dimensionality\n",
    "print(f\"Training set dimension: Input {x_train.shape}, Output {y_train.shape}\")\n",
    "print(f\"Test set dimension: Input {x_test.shape}, Output {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like our input data to lies in the interval $[0, 1]$. If our data does not lies in this interval, we can transform it as:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - x_{min}}{x_{max}-x_{min}}\n",
    "$$\n",
    "\n",
    "Where $x_{min} = \\min(x)$, $x_{max} = \\max(x)$. Note that $x'$ always lies in the interval $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization function\n",
    "normalize_data = (lambda X: ((X - X.min()) / (X.max() - X.min())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is called normalization(min-max feature scaling) and allow us to work easily with the data, speeding up the computation and in some case improving even the results of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (train) data lies in the interval [0, 255]\n",
      "Input (test) data lies in the interval [0, 255]\n",
      "\n",
      "\n",
      "Input (train) data lies in the interval [0.0, 1.0]\n",
      "Input (test) data lies in the interval [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input (train) data lies in the interval [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"Input (test) data lies in the interval [{x_test.min()}, {x_test.max()}]\")\n",
    "    \n",
    "x_train = normalize_data(x_train)\n",
    "x_test = normalize_data(x_test)\n",
    "\n",
    "# Check the interval after normalization\n",
    "print(\"\\n\")\n",
    "print(f\"Input (train) data lies in the interval [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"Input (test) data lies in the interval [{x_test.min()}, {x_test.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y[0]: 9\n",
      "y[0] after the one-hot encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y[0]: {y_train[0]}\")\n",
    "\n",
    "# One hot encode the output variables (needed to compute the output)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "n_classes = len(y_train[0])\n",
    "\n",
    "print(f\"y[0] after the one-hot encoding: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the first model!\n",
    "\n",
    "Now that our data is ready, we can build our first model. As you studied, a Neural Network model is defined as a sequence of *Layers*, which is obtained by composing an Affine Transformation with a Non-Linear Activation function. \n",
    "\n",
    "The simplest possible layer is the **Dense** layer, which is the fully-connected layer describing the operation $\\sigma(Ax + b)$, where $A, b$ are learnable parameters, $A$ is a full matrix, and $\\sigma$ is the activation function. Since **Dense** layers applies to vectors (not images), we first need to flatten our data. This can be done either via the **Flatten** layer or via the **Reshape** layer. Moreover, every model must begin with an **Input** layer, that describes the type of data our model will expect as input.\n",
    "\n",
    "### Summary\n",
    "- Input: First Layer of the Network.\n",
    "- Flatten: Utility Layer. It is used to flatten 3-dimensional data of the form $(d_1, d_2, c)$ to a 1-dimensional array of length $d_1 * d_2 * c$. \n",
    "- Reshape: Utility Layer. It reshape the input in the way you want, as long as the dimensions match.\n",
    "- Dense: Basic Layer. It computes a generic Linear transform followed by a non-linear activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Layers from Keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 12:14:05.474369: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-11 12:14:05.475338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-11 12:14:06.749884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:06.750060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3050 Ti Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.485GHz coreCount: 20 deviceMemorySize: 3.80GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2024-08-11 12:14:06.750077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 12:14:06.751654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 12:14:06.751701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-08-11 12:14:06.753085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-11 12:14:06.753297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-11 12:14:06.754644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-11 12:14:06.755373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-11 12:14:06.758666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-11 12:14:06.758822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:06.759059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:06.759237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-08-11 12:14:06.759584: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 12:14:06.760374: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-11 12:14:06.760521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:06.760680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3050 Ti Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.485GHz coreCount: 20 deviceMemorySize: 3.80GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2024-08-11 12:14:06.760705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 12:14:06.760723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 12:14:06.760734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-08-11 12:14:06.760743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-11 12:14:06.760753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-11 12:14:06.760763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-11 12:14:06.760773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-11 12:14:06.760783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-11 12:14:06.760833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:06.761007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:06.761141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-08-11 12:14:06.761169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 12:14:07.864558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-11 12:14:07.864590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-08-11 12:14:07.864602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-08-11 12:14:07.864829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:07.865040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:07.865219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 12:14:07.865372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3352 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "# Sequential API\n",
    "\n",
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([Flatten(),\n",
    "                    Dense(units=64, activation='relu'),\n",
    "                    Dense(units=10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API \n",
    "\n",
    "\"\"\"\n",
    "This implementation is equivalent to the implemantation above with the Sequential\n",
    "API, but it is written using Functional API.\n",
    "\"\"\"\n",
    "\n",
    "def get_model(input_shape, output_shape):\n",
    "    d1, d2 = input_shape\n",
    "    # Define the model by concatenating Layers\n",
    "    x = Input(shape=(d1, d2))\n",
    "\n",
    "    #h = Flatten()(x)\n",
    "    h = Reshape((d1*d2,), input_shape=(d1, d2))(x)\n",
    "    h = Dense(units=64, activation='relu')(h)\n",
    "\n",
    "    y = Dense(units=output_shape, activation='softmax')(h)\n",
    "\n",
    "    # Get the model\n",
    "    model = Model(x, y)\n",
    "\n",
    "    # Visualize summary of the newly created Model\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why you should use the functional model?\n",
    "\n",
    "For this small use case both the Sequential and Functional implementations of the model are correct and apparently equivalent. The former is easier to implement, since it is only required to define the ordering of the layers one after the other and Tensorflow will concatenate them to build the Neural Network. The Functional API instead is harder since it requires to define not only the list of the Layers, but also the relationship between them. On the other hand, the Functional API will allow to define architecture with complex relationship between layers (e.g. skip connections), which is impossible while using Sequential API.\n",
    "One example of the use of skip connections are the Residual Networks. Resnet were proposed by [He et al.](https://arxiv.org/pdf/1512.03385.pdf) in 2015 to solve the image classification problem. In ResNets, the information from the initial layers is passed to deeper layers by matrix addition. This operation doesnâ€™t have any additional parameters as the output from the previous layer is added to the layer ahead. A single residual block with skip connection looks like this:\n",
    "\n",
    "![Resnet](https://www.researchgate.net/profile/Olarik-Surinta/publication/330750910/figure/fig1/AS:720960386781185@1548901759330/Illustration-of-the-residual-learning-between-a-plain-network-and-b-a-residual.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "To train our model, we first need to **compile** it. Compiling a model means defining a loss function and an optimizer. The loss function should quantify the notion of \"distance\" we want to minimize in our training, while the optimizer is the algorithm that minimize it.\n",
    "\n",
    "In symbols, if we define $f(x; \\theta)$ our model, parameterized by $\\theta$, and we define a loss function $J(\\theta) = \\frac{1}{N}\\sum_{i=1}^N \\ell(f(x^{(i)}; \\theta), y^{(i)})$, training means finding a set of parameters $\\theta^*$ that solves\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_\\theta J(\\theta)\n",
    "$$\n",
    "\n",
    "This is done by initializing our parameters to a random value $\\theta_0$. The default initializer in Keras is Glorot Uniform, but it can be changed. See https://keras.io/api/layers/initializers/ for more informations.\n",
    "Given $\\theta_0$, the Optimizer $g(\\cdot)$ computes a sequence of updating:\n",
    "\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k + \\alpha_k g(\\theta_k)\n",
    "$$\n",
    "\n",
    "where $\\alpha_k$ is the *learning rate*.\n",
    "\n",
    "Compiling a model means defining the loss function $J(\\theta)$ (or, equivalently, $\\ell(\\cdot, \\cdot)$), and the optimizer $g(\\cdot)$. Other setting will be defined in the compiling phase. We will talk about them later since they are not necessary.\n",
    "\n",
    "The most used optimizer in the literature is Adam, which is a powerful alternative to the Stochastic Gradient Descent (you already saw in other courses). For a deep explanation on optimizers, refer to https://arxiv.org/abs/1606.04838 . Other optimizier can be choose, for example:\n",
    "\n",
    "* SGD -> Stochastic Gradient Descent\n",
    "* RMSprop\n",
    "* Adadelta\n",
    "* Adagrad\n",
    "\n",
    "For an explanation of the different kind of optimizers, refer to the official documentation https://keras.io/api/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "d = x_train.shape[-1]\n",
    "\n",
    "model = get_model((d, d), y_train.shape[-1])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is compiled, we can train it. This is done with the *fit* method. To fit the model, we will need some informations.\n",
    "\n",
    "As we said, training works by minimizing $J(\\theta)$ via a sequence of parameters update\n",
    "\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k + \\alpha_k g(\\theta_k)\n",
    "$$\n",
    "\n",
    "When the optimizer is chosen to be a variant of Stochastic Gradient Descent (SGD) (e.g. Adam), it takes as input a batch of data.\n",
    "\n",
    "Briefly, consider a dataset of $N$ elemets. Define a parameter $m$, named *batch size* and, at each iteration, select a random subset of data from the entire dataset, of $m$ elements. Those subsets are named *batches*. Given a batch of data, the optimizer takes it as input and compute one step of the training algorithm. Then, the used batch is removed from the original dataset.\n",
    "\n",
    "After all the dataset is being processed, we say that an *epoch* as been executed. This process is repeated for a (usually fixed) number of epochs. Both the batch size and the number of epochs is passed as input to the *fit* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 12:14:20.114569: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-08-11 12:14:20.131363: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3193945000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 12:14:20.322672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 2s 3ms/step - loss: 0.7176 - accuracy: 0.7551 - val_loss: 0.4247 - val_accuracy: 0.8448\n",
      "Epoch 2/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.4094 - accuracy: 0.8513 - val_loss: 0.3893 - val_accuracy: 0.8585\n",
      "Epoch 3/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3824 - accuracy: 0.8595 - val_loss: 0.4300 - val_accuracy: 0.8415\n",
      "Epoch 4/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8708 - val_loss: 0.3765 - val_accuracy: 0.8635\n",
      "Epoch 5/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8725 - val_loss: 0.3707 - val_accuracy: 0.8675\n",
      "Epoch 6/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8790 - val_loss: 0.3876 - val_accuracy: 0.8633\n",
      "Epoch 7/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8808 - val_loss: 0.3830 - val_accuracy: 0.8662\n",
      "Epoch 8/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8844 - val_loss: 0.3866 - val_accuracy: 0.8643\n",
      "Epoch 9/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3056 - accuracy: 0.8859 - val_loss: 0.3872 - val_accuracy: 0.8637\n",
      "Epoch 10/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8832 - val_loss: 0.3894 - val_accuracy: 0.8658\n",
      "Epoch 11/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.8879 - val_loss: 0.3940 - val_accuracy: 0.8700\n",
      "Epoch 12/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.8896 - val_loss: 0.3791 - val_accuracy: 0.8697\n",
      "Epoch 13/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8961 - val_loss: 0.3712 - val_accuracy: 0.8702\n",
      "Epoch 14/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8937 - val_loss: 0.3884 - val_accuracy: 0.8685\n",
      "Epoch 15/30\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 0.2837 - accuracy: 0.8935 - val_loss: 0.3739 - val_accuracy: 0.8723\n",
      "Epoch 16/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.8952 - val_loss: 0.3883 - val_accuracy: 0.8720\n",
      "Epoch 17/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.8981 - val_loss: 0.4379 - val_accuracy: 0.8538\n",
      "Epoch 18/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8987 - val_loss: 0.3850 - val_accuracy: 0.8748\n",
      "Epoch 19/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.9022 - val_loss: 0.4100 - val_accuracy: 0.8685\n",
      "Epoch 20/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2659 - accuracy: 0.8985 - val_loss: 0.3769 - val_accuracy: 0.8742\n",
      "Epoch 21/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.9022 - val_loss: 0.4138 - val_accuracy: 0.8638\n",
      "Epoch 22/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.9029 - val_loss: 0.4206 - val_accuracy: 0.8697\n",
      "Epoch 23/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.9010 - val_loss: 0.4129 - val_accuracy: 0.8712\n",
      "Epoch 24/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.9043 - val_loss: 0.4053 - val_accuracy: 0.8733\n",
      "Epoch 25/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9038 - val_loss: 0.4041 - val_accuracy: 0.8752\n",
      "Epoch 26/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9060 - val_loss: 0.4149 - val_accuracy: 0.8763\n",
      "Epoch 27/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9031 - val_loss: 0.4481 - val_accuracy: 0.8633\n",
      "Epoch 28/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.9061 - val_loss: 0.4199 - val_accuracy: 0.8723\n",
      "Epoch 29/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9029 - val_loss: 0.4121 - val_accuracy: 0.8700\n",
      "Epoch 30/30\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9077 - val_loss: 0.4354 - val_accuracy: 0.8700\n"
     ]
    }
   ],
   "source": [
    "# Train the model. We save the output of the training in a variable named \"history\".\n",
    "# This variable contains a report of the behavior of the loss during the iterations.\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4519367218017578, 0.8690999746322632]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute model accuracy on the test set.\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
