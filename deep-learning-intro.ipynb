{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a famous library named TensorFlow (which is now available in version 2+) and in particular one of its subpackages, Keras, together with some utilities libraries like: \n",
    "\n",
    "- Matplotlib (for visualization);\n",
    "- Numpy (to work with arrays);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Runtime\n",
    "\n",
    "Neural Network training requires high parallel computation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 10:56:46.899616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Check tensorflow version (must be >2!)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a dataset\n",
    "\n",
    "To train a Neural Network model, we will need to load in memory a dataset. You can load it in lots of ways, depending on the time of data that you need.\n",
    "\n",
    "we will use built-in data on keras. In particoular, we are interested in:\n",
    "\n",
    "- Fashion-MNIST: It is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. \n",
    "\n",
    "we will download the dataset locally and experiment with it.\n",
    "You can visualize the data [here](https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=fashion_mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dimension: Input (60000, 28, 28), Output (60000,)\n",
      "Test set dimension: Input (10000, 28, 28), Output (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Import keras dataset Fashion Mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Check data dimensionality\n",
    "print(f\"Training set dimension: Input {x_train.shape}, Output {y_train.shape}\")\n",
    "print(f\"Test set dimension: Input {x_test.shape}, Output {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like our input data to lies in the interval $[0, 1]$. If our data does not lies in this interval, we can transform it as:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - x_{min}}{x_{max}-x_{min}}\n",
    "$$\n",
    "\n",
    "Where $x_{min} = \\min(x)$, $x_{max} = \\max(x)$. Note that $x'$ always lies in the interval $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization function\n",
    "normalize_data = (lambda X: ((X - X.min()) / (X.max() - X.min())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is called normalization(min-max feature scaling) and allow us to work easily with the data, speeding up the computation and in some case improving even the results of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (train) data lies in the interval [0, 255]\n",
      "Input (test) data lies in the interval [0, 255]\n",
      "\n",
      "\n",
      "Input (train) data lies in the interval [0.0, 1.0]\n",
      "Input (test) data lies in the interval [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input (train) data lies in the interval [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"Input (test) data lies in the interval [{x_test.min()}, {x_test.max()}]\")\n",
    "    \n",
    "x_train = normalize_data(x_train)\n",
    "x_test = normalize_data(x_test)\n",
    "\n",
    "# Check the interval after normalization\n",
    "print(\"\\n\")\n",
    "print(f\"Input (train) data lies in the interval [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"Input (test) data lies in the interval [{x_test.min()}, {x_test.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y[0]: 9\n",
      "y[0] after the one-hot encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y[0]: {y_train[0]}\")\n",
    "\n",
    "# One hot encode the output variables (needed to compute the output)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "n_classes = len(y_train[0])\n",
    "\n",
    "print(f\"y[0] after the one-hot encoding: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the first model!\n",
    "\n",
    "Now that our data is ready, we can build our first model. As you studied, a Neural Network model is defined as a sequence of *Layers*, which is obtained by composing an Affine Transformation with a Non-Linear Activation function. \n",
    "\n",
    "The simplest possible layer is the **Dense** layer, which is the fully-connected layer describing the operation $\\sigma(Ax + b)$, where $A, b$ are learnable parameters, $A$ is a full matrix, and $\\sigma$ is the activation function. Since **Dense** layers applies to vectors (not images), we first need to flatten our data. This can be done either via the **Flatten** layer or via the **Reshape** layer. Moreover, every model must begin with an **Input** layer, that describes the type of data our model will expect as input.\n",
    "\n",
    "### Summary\n",
    "- Input: First Layer of the Network.\n",
    "- Flatten: Utility Layer. It is used to flatten 3-dimensional data of the form $(d_1, d_2, c)$ to a 1-dimensional array of length $d_1 * d_2 * c$. \n",
    "- Reshape: Utility Layer. It reshape the input in the way you want, as long as the dimensions match.\n",
    "- Dense: Basic Layer. It computes a generic Linear transform followed by a non-linear activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Layers from Keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 11:26:09.798152: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-11 11:26:09.799796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-11 11:26:09.838575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:09.838792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3050 Ti Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.485GHz coreCount: 20 deviceMemorySize: 3.80GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2024-08-11 11:26:09.838829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 11:26:09.848970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 11:26:09.849058: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-08-11 11:26:09.856204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-11 11:26:09.857607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-11 11:26:09.864359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-11 11:26:09.866169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-11 11:26:09.875214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-11 11:26:09.875494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:09.875919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:09.876063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-08-11 11:26:09.876469: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 11:26:09.877211: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-11 11:26:09.877355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:09.877520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3050 Ti Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.485GHz coreCount: 20 deviceMemorySize: 3.80GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2024-08-11 11:26:09.877550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 11:26:09.877571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-11 11:26:09.877582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-08-11 11:26:09.877592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-11 11:26:09.877601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-11 11:26:09.877613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-11 11:26:09.877623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-11 11:26:09.877633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-11 11:26:09.877700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:09.877889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:09.878018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-08-11 11:26:09.878048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-11 11:26:11.211380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-11 11:26:11.211420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-08-11 11:26:11.211429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-08-11 11:26:11.211778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:11.212017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:11.212205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-11 11:26:11.212358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 110 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2024-08-11 11:26:11.214383: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 110.69M (116064256 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# Sequential API\n",
    "\n",
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([Flatten(),\n",
    "                    Dense(units=64, activation='relu'),\n",
    "                    Dense(units=10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API \n",
    "\n",
    "\"\"\"\n",
    "This implementation is equivalent to the implemantation above with the Sequential\n",
    "API, but it is written using Functional API.\n",
    "\"\"\"\n",
    "\n",
    "def get_model(input_shape, output_shape):\n",
    "    d1, d2 = input_shape\n",
    "    # Define the model by concatenating Layers\n",
    "    x = Input(shape=(d1, d2))\n",
    "\n",
    "    #h = Flatten()(x)\n",
    "    h = Reshape((d1*d2,), input_shape=(d1, d2))(x)\n",
    "    h = Dense(units=64, activation='relu')(h)\n",
    "\n",
    "    y = Dense(units=output_shape, activation='softmax')(h)\n",
    "\n",
    "    # Get the model\n",
    "    model = Model(x, y)\n",
    "\n",
    "    # Visualize summary of the newly created Model\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why you should use the functional model?\n",
    "\n",
    "For this small use case both the Sequential and Functional implementations of the model are correct and apparently equivalent. The former is easier to implement, since it is only required to define the ordering of the layers one after the other and Tensorflow will concatenate them to build the Neural Network. The Functional API instead is harder since it requires to define not only the list of the Layers, but also the relationship between them. On the other hand, the Functional API will allow to define architecture with complex relationship between layers (e.g. skip connections), which is impossible while using Sequential API.\n",
    "One example of the use of skip connections are the Residual Networks. Resnet were proposed by [He et al.](https://arxiv.org/pdf/1512.03385.pdf) in 2015 to solve the image classification problem. In ResNets, the information from the initial layers is passed to deeper layers by matrix addition. This operation doesnâ€™t have any additional parameters as the output from the previous layer is added to the layer ahead. A single residual block with skip connection looks like this:\n",
    "\n",
    "![Resnet](https://www.researchgate.net/profile/Olarik-Surinta/publication/330750910/figure/fig1/AS:720960386781185@1548901759330/Illustration-of-the-residual-learning-between-a-plain-network-and-b-a-residual.ppm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
